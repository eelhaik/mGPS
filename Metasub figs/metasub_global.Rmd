---
title: "mGPS - MetaSUB microbiome results and figures"
output: 
  github_document
    
---

```{r setup, include=FALSE}
#knitr::opts_chunk$set(echo = TRUE)
#knitr::opts_knit$set( root.dir = "~/Documents/Microbiome-mapping/MetaSUB-code/Updated_mGPS_figs" )
#knitr::opts_chunk$set(cache =TRUE)
#knitr::opts_chunk$set(fig.width=13, fig.height=8) 
```

This notebook outlines the procedure used to generate MetaSUB global predictions for the mGPS paper, including the code used for figures.  

# Data Preperation

Load dependencies

```{r, echo=T, eval = T}
library(sp)
library(rworldmap)
library(caret)
library(maps)
library(randomForest)
library(geosphere)
library(doParallel)
library(caret)
library(plyr)
library(maptools)
library(rgeos)
library(mapplots)
```

```{r, echo = F}
load("~/Documents/Microbiome-mapping/MetaSUB-code/mGPS2.RData")
source("mGPS.r")
```

First we import the metasub datasets for metadata (city, latitude, longitude etc) and bacterial abundance data. Merge these sets by sample ID. 

Control samples are be removed for obvious reasons. 
```{r data preperation, eval=F}
#Import data sets 
complete_meta <- read.csv(file = "/Users/leomccarthy/Documents/Microbiome-mapping/DATA/complete_metadata.csv", header = TRUE)
taxa_abund <-read.csv("/Users/leomccarthy/Documents/Microbiome-mapping/DATA/metasub_taxa_abundance.csv", header = T)
taxa_abund <- unique(taxa_abund)

#merge bacterial and meta data
metasub_data <- merge(complete_meta,taxa_abund,by.x="uuid",by.y="uuid")

#Remove control samples
control_samples <- c( which(metasub_data$city %in% c("control", "other_control","neg_control","other","pos_control")), which(metasub_data$control_type %in% c("ctrl cities","negative_control","positive_control"))) 
metasub_data <- droplevels(metasub_data[-c(control_samples), ])


```

We will also remove some samples for which the origin isn't clear e.g. the name of the origin does match the co-ordinates. Samples from bouroughs within london will be re-labelled simply as London for consistency. 

For global predictions we remove cities for which there was insufficient sampling data. 

```{r}
#re-label london boroughs 
metasub_data$city[metasub_data$city %in% c("kensington","islington")] <- "london" 
metasub_data <- droplevels(metasub_data)

#remove sparse samples locations and dubiously labelled samples. 

small_cities <-  names(which(summary(metasub_data$city) < 8))
remove_samples <- which(metasub_data$city %in%  c("antarctica", small_cities))
metasub_data <- droplevels(metasub_data[-c(remove_samples), ])


```




```{r}
#Correction of identified misslabelling of data 
metasub_data$latitude[metasub_data$city == "kyiv"] <- metasub_data$city_latitude[metasub_data$city == "kyiv"]
metasub_data$longitude[metasub_data$city == "kyiv"] <- metasub_data$city_longitude[metasub_data$city == "kyiv"]
metasub_data$continent[metasub_data$city == "porto"] <- "europe"
```

Not all of the samples have exact origin co-ordinates recorded, for the purposes of global predictions we substitute the central co-ordinates of the city of origin for the missing exact co-ordiantes, found in the city meta-data. . 

```{r}
#impute unknown exact co-ords for city co-ords
metasub_data[is.na(metasub_data$latitude),]$latitude <- metasub_data[is.na(metasub_data$latitude),]$city_latitude
metasub_data[is.na(metasub_data$longitude),]$longitude <- metasub_data[is.na(metasub_data$longitude),]$city_longitude

#correction to some incorrect city co-ords for a few london samples
metasub_data[metasub_data$city == "london",]$city_latitude <- 51.50853
metasub_data[metasub_data$city == "london",]$city_longitude <- -0.12574

```

# Feature selection

This dataset contains rather a large amount of predictor variables, many of which will be random noise and detrimental to both model accuracy and computation time. 

To select an optimum set of variables for each of the target variables of interest (city,latitude and longitude) we use recursive feature elimination with random forests. The caret function "rfe" uses re-sampling and external validation to protect against selecting features that lead us to overfit the training data. More information is avalable at  https://topepo.github.io/caret/recursive-feature-elimination.html 

```{r,eval=F}
#Activate parallel processing 
registerDoParallel(parallel::detectCores() - 1)

#recursive feature elimination for the target variable "city"
rfe_ctrl <- rfeControl(functions = rfFuncs,
                   method = "cv",
                   number =  5,
                   verbose = FALSE,
                   allowParallel = TRUE)

set.seed(123)
featureElimination <- rfe(x = metasub_data[, c(43:3711)],y = metasub_data$city,
                 sizes = c(50,100,200,300,500,1500),
                 rfeControl = rfe_ctrl,
                 tuneLength = 1
                 )

optimumVarsCity <- featureElimination$optVariables


```

Fig S9, effect of removing redundsnt taxa.

```{r}
plot(featureElimination$results$Variables, featureElimination$results$Accuracy, type = "b", xlab = "", ylab = "", cex = 1.5, col = "dodgerblue")
title(ylab="Accuracy of random forest classifier",xlab = "Number of taxa", mgp=c(2.5,1.5,1),cex.lab=1)
points(featureElimination$results$Variables[3],featureElimination$results$Accuracy[3], pch = 20, cex = 1.2,col = "dodgerblue")

```

Looking at the results it's clear using all the variables is not optimal. 200 variables is the optimum subset from these results so we will use this as our optimum subset of bacterial species for further analysis when aiming to predict city of origin. 

Top 25 geographic indicator species

```{r}
#Extract and rank species importance
v <- varImp(featureElimination$fit, type = 1, scale = F)
v[,"taxa"] <- row.names(v)
v <- v[order(v$Overall,decreasing = T),]
top_species <- v[1:25,"taxa"]

#plot

par(font = 3)
dotchart(rev(v[1:25,"Overall"])*100,labels= rev(top_species),cex=1.2,pt.cex = 1.3,
         xlab="Mean decrease in accuracy", mgp = c(2.2,0,0))

```


Fig S11, Geographic distribution of dbundance for top 25 geo indicator species

```{r}


ag <- aggregate(metasub_data[, top_species], by = list(metasub_data$city), FUN = median)
city_locations <- aggregate(metasub_data[,c("city_longitude","city_latitude")], by = list(metasub_data$city), FUN = mean)
city_abund <- merge(city_locations,ag, by = "Group.1")


levels(metasub_data$city)
for (i in top_species){
  if (max(city_abund[,i]) == 0 ){city_abund[,i] <- 0} 
     else{ city_abund[,i] <- (city_abund[,i]- min(city_abund[,i]) )/(max(city_abund[,i])- min(city_abund[,i]))
  }
}



pal <- palette <-c( "gold2","brown","dodgerblue3","darkseagreen2","darkorchid4","darkcyan","orangered2","olivedrab2","deeppink2","darkslateblue","mediumspringgreen","gray21","royalblue","yellow1","orange","purple1","cyan2","burlywood","aquamarine2","chartreuse4","deeppink4","cadetblue4","goldenrod1","firebrick2","hotpink")
p=5

for (p in 1:25){


#png(paste("Species_abundance_",p,".png", sep = ""), width = 12, height = 8, units = "in", res = 600)

  ggplot(map, aes(x = long, y = lat, group = group)) +
  geom_polygon(fill="grey", colour = "darkgrey", size = 0.4)+
  coord_quickmap(xlim = c(-145,165), ylim =c(-50,70))+
  theme_classic()+
  theme(panel.background = element_rect(fill = "lightskyblue1",
                                colour = "lightskyblue1",
                                size = 0.5, linetype = "solid"))+
  geom_point(data = city_abund, aes(x = city_longitude,y = city_latitude, 
                                        group = Group.1, color = city_abund[,p+3]), size = 9)+
  
  scale_color_gradient(low = "white", high = pal[p], na.value = NA,name = "Relative abundance \n(normalised)", limits = c(0,1), breaks = waiver(),n.breaks = 6)+
  

  theme(legend.position = c(0.08, 0.3),
        legend.background = element_rect(fill="lightskyblue1", 
        size=2, linetype="solid"),legend.key.size = unit(0.9, "cm"), 
        legend.text = element_text(size = 9, face = "bold"), 
        legend.title = element_text(size = 12, face = "bold"),
        plot.title = element_text(size = 18, face = "bold"),
        axis.line=element_blank(),axis.text.x=element_blank(),
          axis.text.y=element_blank(),axis.ticks=element_blank(),
          axis.title.x=element_blank(),
          axis.title.y=element_blank(),
        plot.margin = unit( c(t = 0, r = -.1, b = -.2, l = 0), "cm"))+
  ggtitle(colnames(city_abund)[p+3],)+
  labs(x="", y="")
  
  ggsave(paste("Species_abundance",p,".png", sep = ""),plot = last_plot(),device = NULL,path = NULL,scale = 1,width = 12,height = 5.1,dpi = 600,limitsize = TRUE,)
 

}



```


# Modeling 

Our model makes use of classifier/regressior chaining, in order to produce multi output predictions for city,latittude and longitude, more details can be found in the mGPS paper. This techniques involves chaining predictions for a series of outputs using them as input features for the next level model. In this case 4 chained XGboost models are used with hyperparameter tuning carried out by 5-fold cross validation of the trainng set using grid search methods at every level. 

Here this function here takes 4 arguments: a training set, a test set, a target class which in our case is origin city and a set of bacterial species to use as predictor variables. The function outputs the city,latitude and longitude predictions from applying this model to the input test set. 

Load mGPS model

```{r}
source("mGPS.r")
```


Using our algorithm will will employ 5-fold validation on the metasub data set in order to generate predictions for city, latitude and longitude.  

```{r, eval=FALSE, echo=TRUE}
#generate 5 stratified folds for test predictions.
set.seed(18)
trainFolds <-  createFolds(metasub_data$city, k = 5, returnTrain = T)



GeoPreds <- list()

#iteratively train the model on each of the 5 training folds and generate predictions using the coresponding test fold.
for (i in 1:5){
  
  train <- metasub_data[trainFolds[[i]],]
  test <- metasub_data[-trainFolds[[i]],]
  
  testPreds <-mGPS(training = train, testing = test, classTarget = "city",variables = optimumVarsCity)
  GeoPreds[[i]] <- testPreds
  
}


#Combine these test predictions into one data set 
add_preds <- list()
for (i in 1:5){
  
  add_preds[[i]] <- cbind(metasub_data[-trainFolds[[i]],] , 
                          "cityPred"= GeoPreds[[i]][[1]], 
                          "latPred" = GeoPreds[[i]][[2]], 
                          "longPred" = GeoPreds[[i]][[3]] )
  
  
  
}

MetasubDataPreds <- rbind.fill(add_preds)
MetasubDataPreds[MetasubDataPreds$longPred > 180,"longPred"] <- 180.000

#MetasubDataPreds <-  MetasubDataPreds[,c("uuid","continent","city","latitude","longitude","cityPred","latPred","longPred")]

```

The final stage of this model is to adjust any predicted co-ordiantes that don't lie on land. This step makes the assumption that all future tetsing data will be taken from land we beleive this is a valid approach to take. 

```{r, eval=FALSE, echo=TRUE}
##Final stage is to adjust any co-ordinates that are in the sea and pull them to the nearset land mass

#get world coastlines
coastlines <- cbind("x"  = SpatialLines2map(coastsCoarse)$x ,"y" =SpatialLines2map(coastsCoarse)$y)
   coastlines <- coastlines[complete.cases(coastlines),]
      coastlines <- coastlines[coastlines[,1] < 180 ,]


#Function to find the nearest land point of any GPS co-ordinates
find_coast <- function(long,lat){
    distances_from_coastline <-  spDistsN1(coastlines , c(long,lat), longlat = TRUE)
    
                                    closest_point <-  which.min(distances_from_coastline)
                                    new_coords <- coastlines[closest_point,]
    
                                       return(new_coords)
 
                                     }




      #Find points than need adjusting 
      GPS_where <- map.where(database = "world", MetasubDataPreds$longPred, MetasubDataPreds$latPred)
         toAdjust <- MetasubDataPreds[which(is.na(GPS_where)),]
         adjusted <- mapply(find_coast, long = toAdjust$longPred, lat = toAdjust$latPred )
         
         
      #Adjust points 
            MetasubDataPreds[which(is.na(GPS_where)), "longPred"] <- adjusted[1,]
            MetasubDataPreds[which(is.na(GPS_where)), "latPred"] <- adjusted[2,]
            
```


Get Prediction results
```{r}
na_levels <- setdiff(levels(MetasubDataPreds$city),levels(MetasubDataPreds$cityPred))
levels(MetasubDataPreds$cityPred ) <- c(levels(MetasubDataPreds$cityPred) , na_levels)

res <- confusionMatrix(MetasubDataPreds$cityPred, MetasubDataPreds$city)[[4]]
res <- round(res, 2)

mean(res[,"Specificity"])

#Print test results 
print(c(mean(MetasubDataPreds$cityPred ==MetasubDataPreds$city)
   ,RMSE(MetasubDataPreds$latPred, MetasubDataPreds$latitude),
       RMSE(MetasubDataPreds$longPred, MetasubDataPreds$longitude)))

```


Fimd correlation with city population
```{r}
CityPop <- read.csv(file = "Geodata/CityPopulations.csv", header = TRUE)

city_names <- c("Auckland" ,"Baltimore" ,"Barcelona", "Berlin","Bogota", 
                "Brisbane","Denver","Doha" ,"Fairbanks","Hamilton",
                "Hanoi","Hong Kong","Ilorin","Kuala Lumpur","Kyiv",
                "Lisbon", "London" ,"Marseille" , "Minneapolis", "Naples"  ,"New York City",
                "Offa" ,"Oslo" ,"Paris","Porto","Rio de Janeiro",
                "Sacramento","San Francisco" ,"Santiago" , "Sao Paulo" ,"Sendai",
                "Seoul","Singapore", "Sofia","Stockholm","Taipei",
                "Tokyo","Vienna","Yamaguchi","Zurich")
city_pop <- data.frame()
for (i in 1:length(levels(MetasubDataPreds$city))){ 
  this_city <- levels(MetasubDataPreds$city)[i]
  city_pop[i,"city_size"] <-  CityPop[i,"population"]
  city_pop[i,"balanced_acc"] <-  res[ paste("Class:", this_city),"Balanced Accuracy"]
  city_pop[i,"within_500"] <-  mean(MetasubDataPreds[MetasubDataPreds$city == this_city, "Distance_from_origin"] < 500)
}
```

Fig S3 correlation with city population

```{r}
options(scipen = 5)
plot(city_pop$city_size,100*city_pop[,"within_500"], xlab ="City population",
     ylab = "Predictions within 500km (%)", pch = 16, cex = 0.7)
text(city_pop$city_size ,100*city_pop[,"within_500"] + 1 ,labels = city_names, cex = 0.6)


```



Next use predicted co-ordinates to a generate the distance of predictions from the true origin using the haversine formula. 


```{r, eval = T, echo = T}
#Using lat long predictions determine distance (km) of the prediction from true origin using haversine distance. 

for (i in 1:nrow(MetasubDataPreds)){
  MetasubDataPreds[i,"Distance_from_origin"] <- distm(c(MetasubDataPreds[i,"longPred"],MetasubDataPreds[i,"latPred"]), c(MetasubDataPreds[i,"longitude"],MetasubDataPreds[i,"latitude"]), fun = distHaversine)/1000
}


#Print distance from origin results 
print(c(mean(MetasubDataPreds$Distance_from_origin ),
median(MetasubDataPreds$Distance_from_origin ),
mean(MetasubDataPreds$Distance_from_origin < 250)))

```




Fig 1, plot the predicted origin of each global sample. Coloured by continent of origin. City classification prediction accuracy is showm by the pie charts. 

```{r}

#####world map showing by continent
map <- getMap(resolution = "coarse")

palette <-c( "darkorchid4","gold2","dodgerblue3","brown","orangered2","mediumspringgreen","deeppink2")

png("Global_msub.png", width = 13,height = 8, units = 'in', res = 600)
plot(map, xlim = c(-165,168), col = "grey",border = "darkgrey", xlab = "", ylab = '', bg = "lightskyblue1")
title(ylab="Latitude",xlab = "Longitude", mgp=c(2,1,0),cex.lab=1.2)
#find coord preds by region
for ( i in 1:length(levels(MetasubDataPreds$continent))){
  this_continent <- levels(MetasubDataPreds$continent)[i]
  find_lats <- MetasubDataPreds[MetasubDataPreds[,"continent"] == this_continent,][,"latPred"]
  find_longs <- MetasubDataPreds[MetasubDataPreds[,"continent"] == this_continent,][,"longPred"]
  
  #plot predicted co-ordinates
  points(find_longs, find_lats, col = palette[i], pch = "+", cex = 1.2)
  
  #plot city prediction accuravy by continent as pies
  correctly_pred <-  mean(MetasubDataPreds[MetasubDataPreds$continent == this_continent,"cityPred"]== 
                                 MetasubDataPreds[MetasubDataPreds$continent == this_continent,"city"]) 
  incorrectly_pred <- (1 - correctly_pred) 

  
  
  
  continent_lats <- c(55,69,8,40,-40,-10,-5)
  continent_longs <- c(125,0,60,-130,140,-80,5)
  
  add.pie(z = c(correctly_pred, incorrectly_pred), x = continent_longs[i], y = continent_lats[i]
             ,edges=200,
             radius=10,
             col=c(palette[i],"black") , labels = ""
  )
}

#Plot city sampling locations
map.axes(cex.axis = 1.1)
par(fig = c(0,0.4,0.0,0.5), new = T) 
plot(map,xlim = c(-165,168), col = "grey", border = "darkgrey", bg ="lightskyblue1")
for ( i in 1:length(levels(MetasubDataPreds$continent))){
  this_continent <- levels(MetasubDataPreds$continent)[i]
  find_lats <- MetasubDataPreds[MetasubDataPreds$continent == this_continent,]$city_latitude
  find_longs <- MetasubDataPreds[MetasubDataPreds$continent == this_continent,]$city_longitude
  
  points(find_longs, find_lats, col = palette[i], pch = 17, cex = 1)
}

legend(-165,-15, c("East Asia","Eurpoe","Middle East",
                 "North America",
                 "Oceania",
                 "South America",
                 "Sub Saharan Afica"), pch = 17, col = palette, cex = 0.5, bg ="lightskyblue1")
box( col = 'black')
dev.off()

                    
```


```{r}
map <- getMap(resolution = "low")
palette <-c( "gold2","brown","dodgerblue3","darkorchid4","orangered2","olivedrab2","deeppink2","mediumspringgreen", "gray21","royalblue","yellow1","orange","purple1","cyan2")
```

Fig 1 Europe

```{r}
europe <- droplevels(MetasubDataPreds[MetasubDataPreds$continent == "europe",])

png("Eu_msub.png", width = 13,height = 8, units = 'in', res = 600)
plot(map,xlim = c(-30,50), ylim = c(30,60), col = "grey", border = "grey40", axes =F, bg = "lightskyblue1")
for (i in 1:length(levels(europe$city))){
  this_city <- levels(europe$city)[i]
  find_lats <- europe[europe[,"city"] == this_city,]$latPred
  find_longs <- europe[europe[,"city"] == this_city,]$longPred
  
  points(find_longs, find_lats, col = palette[i], pch = "+", cex = 1.5)
  
}

for (i in 1:length(levels(europe$city))){
  this_city <- levels(europe$city)[i]
  
  city_centre.lat <- europe[europe[,"city"] == this_city,]$city_latitude
  city_centre.long <- europe[europe[,"city"] == this_city,]$city_longitude
  
  points(city_centre.long, city_centre.lat, col = "black", bg =palette[i] ,pch = 24, cex = 1.5)
}

legend(42,60, legend = c("Barcelona","Berlin", "Kyiv", "Lisbon", "London","Marseille",
                          "Naples", "Oslo", "Paris", "Porto", "Sofia", "Stockholm", "Vienna", "Zurich"), col = c(palette),pch = 17, box.lty = 1, cex = 1.1, bg = "lightskyblue1")

#map.axes(cex.axis = 0.8)
map.scale(x=-28, cex = 1)
dev.off()
```


Fig 1 North America 

```{r}

palette <-c( "gold2","darkorchid4","dodgerblue3","mediumspringgreen","orangered2","olivedrab2","deeppink2")
north_america <- droplevels(MetasubDataPreds[MetasubDataPreds$continent == "north_america",])

png("NA_msub.png", width = 13,height = 8, units = 'in', res = 600)
plot(map,xlim = c(-150,0), ylim = c(10,70), col = "grey", border = "grey40", axes =F, bg = "lightskyblue1")
for (i in 1:length(levels(north_america$city))){
  this_city <- levels(north_america$city)[i]
  find_lats <- north_america[north_america[,"city"] == this_city,]$latPred
  find_longs <- north_america[north_america[,"city"] == this_city,]$longPred

  points(find_longs, find_lats, col = palette[i], pch = "+", cex = 1.5)
 
}

for (i in 1:length(levels(north_america$city))){
  this_city <- levels(north_america$city)[i]
 
  city_centre.lat <- north_america[north_america[,"city"] == this_city,]$city_latitude
  city_centre.long <- north_america[north_america[,"city"] == this_city,]$city_longitude
  
  points(city_centre.long, city_centre.lat, col = "black", bg =palette[i] ,pch = 24, cex = 1.5)
}

legend(-27,70, legend = c("Baltimore","Denver","Fairbanks",
                          "Minneapolis","New York City", "Sacramento","San Francisco"), col = c(palette),pch = 17, box.lty = 1, cex = 1.1, bg = "lightskyblue1")

#map.axes(cex.axis = 0.8)
map.scale(x=-54, cex = 1)
dev.off()
```

Fig 1 South America
```{r}
palette <-c( "gold2","darkorchid4","dodgerblue3","deeppink2")
south_america <- droplevels(MetasubDataPreds[MetasubDataPreds$continent == "south_america",])

png("Sa_msub.png", width = 13,height = 8, units = 'in', res = 600)
plot(map,xlim = c(-90,5), ylim = c(-55,30),col = "grey", border = "grey40", axes =F, bg = "lightskyblue1")
for (i in 1:length(levels(south_america$city))){
  this_city <- levels(south_america$city)[i]
  find_lats <- south_america[south_america[,"city"] == this_city,]$latPred
  find_longs <- south_america[south_america[,"city"] == this_city,]$longPred
  
  points(find_longs, find_lats, col = palette[i], pch = "+", cex = 1.5)
  
}
for (i in 1:length(levels(south_america$city))){
  this_city <- levels(south_america$city)[i]
  
  city_centre.lat <- south_america[south_america[,"city"] == this_city,]$city_latitude
  city_centre.long <- south_america[south_america[,"city"] == this_city,]$city_longitude
  
  points(city_centre.long, city_centre.lat, col = "black", bg =palette[i] ,pch = 24, cex = 1.5)
}
legend(20,20, legend = c("Bogota","Rio de Janeiro","Santiago","Sao Paulo"), col = c(palette),pch = 17, box.lty = 1, cex = 1.1, bg = "lightskyblue1")

#map.axes(cex.axis = 0.8)
map.scale(-110,cex = 1)
dev.off()
```




Fig 1 south east asia 

```{r}
east_asia <- droplevels(MetasubDataPreds[MetasubDataPreds$continent == "east_asia",])
palette <-c( "gold2","darkorchid4","dodgerblue3","purple1","orangered2","olivedrab2","deeppink2","mediumspringgreen", "gray21")

png("EA_msub.png", width = 13,height = 8, units = 'in', res = 600)
plot(map,xlim = c(95,100), ylim = c(-15,50), col = "grey", border = "grey40", axes =F, bg = "lightskyblue1")
for (i in 1:length(levels(east_asia$city))){
  this_city <- levels(east_asia$city)[i]
  find_lats <- east_asia[east_asia[,"city"] == this_city,]$latPred
  find_longs <- east_asia[east_asia[,"city"] == this_city,]$longPred
  
  points(find_longs, find_lats, col = palette[i], pch = "+", cex = 1.5)
  #points(city_centre.long, city_centre.lat, col = "black", bg =palette[i] ,pch = 24, cex = 1.5)
}
for (i in 1:length(levels(east_asia$city))){
  this_city <- levels(east_asia$city)[i]

  city_centre.lat <- east_asia[east_asia[,"city"] == this_city,]$city_latitude
  city_centre.long <- east_asia[east_asia[,"city"] == this_city,]$city_longitude
  
  points(city_centre.long, city_centre.lat, col = "black", bg =palette[i] ,pch = 24, cex = 1.5)
}

legend(145,50, legend = c("Hanoi","Hong Kong",
                          "Kuala Lumpur","Sendai","Seoul",
                          "Singapore","Taipei","Tokyo",
                          "Yamaguchi"),  col = c(palette),pch = 17, box.lty = 1, cex = 1.1, bg = "lightskyblue1")
#map.axes(cex.axis = 0.8)
map.scale(60,cex = 1)
dev.off()
```


Fig 1 Africa and middle east

```{r}
palette <-c( "deeppink2","darkorchid4","gold2")
sub_saharan_africa <- droplevels(MetasubDataPreds[MetasubDataPreds$continent %in%  c('sub_saharan_africa','middle_east'),] )

png("AF_msub.png", width = 13,height = 8, units = 'in', res = 600)
plot(map,xlim = c(10,45), ylim = c(-35,40), col = "grey", border = "grey40", bg = "lightskyblue1")
for (i in 1:length(levels(sub_saharan_africa$city))){
  this_city <- levels(sub_saharan_africa$city)[i]
  find_lats <- sub_saharan_africa[sub_saharan_africa[,"city"] == this_city,]$latPred
  find_longs <- sub_saharan_africa[sub_saharan_africa[,"city"] == this_city,]$longPred
 
  points(find_longs, find_lats, col = palette[i], pch = "+", cex = 1.5)
  
}
for (i in 1:length(levels(sub_saharan_africa$city))){
  this_city <- levels(sub_saharan_africa$city)[i]
  
  city_centre.lat <- sub_saharan_africa[sub_saharan_africa[,"city"] == this_city,]$city_latitude
  city_centre.long <- sub_saharan_africa[sub_saharan_africa[,"city"] == this_city,]$city_longitude
 
  points(city_centre.long, city_centre.lat, col = "black", bg =palette[i] ,pch = 24, cex = 1.5)
}
legend(80,40, legend = c("Doha","Ilorin", "Offa"), col = c(palette),pch = 17, box.lty = 1, cex = 1.1, bg = "lightskyblue1")

#map.axes(cex.axis = 0.8)
map.scale(cex = 1)
dev.off()
```


Fig 1 Oceania

```{r}
palette <-c( "deeppink2","darkorchid4","gold2")
oceania <- droplevels(MetasubDataPreds[MetasubDataPreds$continent == "oceania",])

png("Aus_msub.png", width = 13,height = 8, units = 'in', res = 600)

plot(map,xlim = c(80,170), ylim = c(-50,30), col = "grey", border = "grey40", bg = "lightskyblue1")
for (i in 1:length(levels(oceania$city))){
  this_city <- levels(oceania $city)[i]
  find_lats <- oceania[oceania [,"city"] == this_city,]$latPred
  find_longs <- oceania[oceania [,"city"] == this_city,]$longPred
  city_centre.lat <- oceania[oceania [,"city"] == this_city,]$city_latitude
  city_centre.long <- oceania[oceania [,"city"] == this_city,]$city_longitude
  points(find_longs, find_lats, col = palette[i], pch = "+", cex = 1.5)
  points(city_centre.long, city_centre.lat, col = "black", bg =palette[i] ,pch = 24, cex = 1.5)
}
legend(175,20, legend = c("Auckland", "Brisbane", "Hamilton"), col = c(palette),pch = 17, box.lty = 1, cex = 1.1, bg = "lightskyblue1")

#map.axes(cex.axis = 0.8)
map.scale(cex = 1)

dev.off()
```


Calculate distance from origin for Fig S1

```{r}
city_names <- c("Auckland" ,"Baltimore" ,"Barcelona", "Berlin","Bogota", 
                "Brisbane","Denver","Doha" ,"Fairbanks","Hamilton",
                "Hanoi","Hong Kong","Ilorin","Kuala Lumpur","Kyiv",
                "Lisbon", "London" ,"Marseille" , "Minneapolis", "Naples"  ,"New York City",
                "Offa" ,"Oslo" ,"Paris","Porto","Rio de Janeiro",
                "Sacramento","San Francisco" ,"Santiago" , "Sao Paulo" ,"Sendai",
                "Seoul","Singapore", "Sofia","Stockholm","Taipei",
                "Tokyo","Vienna","Yamaguchi","Zurich")


bar_df1 <- data.frame(row.names = c(city_names, "Overall"))


for (i in 1: length(levels(MetasubDataPreds$city))){
  this_city <- levels(MetasubDataPreds$city)[i]
  prop <- mean(MetasubDataPreds[MetasubDataPreds$city == this_city,][,"Distance_from_origin"] < 100)
  bar_df1[i+1,"0 - 100km"] <- prop
  
  overall_prop <- mean(MetasubDataPreds[,"Distance_from_origin"] < 100)
  bar_df1[ 1,"0 - 100km"] <- overall_prop
}


for (i in 1: length(levels(MetasubDataPreds$city))){
  this_city <- levels(MetasubDataPreds$city)[i]
  prop <- mean(MetasubDataPreds[MetasubDataPreds$city == this_city,][,"Distance_from_origin"] > 100 & MetasubDataPreds[MetasubDataPreds$city == this_city,][,"Distance_from_origin"] < 500)
  bar_df1[i+1,"100 - 500km"] <- prop
  
  overall_prop <-mean(MetasubDataPreds[,"Distance_from_origin"] > 100 & MetasubDataPreds[,"Distance_from_origin"] < 500)
  bar_df1[ 1,"100 - 500km"] <- overall_prop
}

for (i in 1: length(levels(MetasubDataPreds$city))){
  this_city <- levels(MetasubDataPreds$city)[i]
  prop <- mean(MetasubDataPreds[MetasubDataPreds$city == this_city,][,"Distance_from_origin"] > 500 & MetasubDataPreds[MetasubDataPreds$city == this_city,][,"Distance_from_origin"] < 1000)
  bar_df1[i+1,"500 - 1000km"] <- prop
  
  overall_prop <- mean(MetasubDataPreds[,"Distance_from_origin"] > 500 & MetasubDataPreds[,"Distance_from_origin"] < 1000)
  bar_df1[ 1,"500 - 1000km"] <- overall_prop
}

for (i in 1: length(levels(MetasubDataPreds$city))){
  this_city <- levels(MetasubDataPreds$city)[i]
  prop <- mean(MetasubDataPreds[MetasubDataPreds$city == this_city,][,"Distance_from_origin"] > 1000 & MetasubDataPreds[MetasubDataPreds$city == this_city,][,"Distance_from_origin"] < 2000)
  bar_df1[i+1,"1000 - 2000km"] <- prop
  
  overall_prop <- mean(MetasubDataPreds[,"Distance_from_origin"] > 1000 & MetasubDataPreds[,"Distance_from_origin"] < 2000)
  bar_df1[ 1,"1000 - 2000km"] <- overall_prop
}
for (i in 1: length(levels(MetasubDataPreds$city))){
  this_city <- levels(MetasubDataPreds$city)[i]
  prop <- mean(MetasubDataPreds[MetasubDataPreds$city == this_city,][,"Distance_from_origin"] > 2000 & MetasubDataPreds[MetasubDataPreds$city == this_city,][,"Distance_from_origin"] < 3000)
  bar_df1[i+1,"2000 - 3000km"] <- prop
  
  overall_prop <- mean(MetasubDataPreds[,"Distance_from_origin"] > 2000 & MetasubDataPreds[,"Distance_from_origin"] < 3000)
  bar_df1[1,"2000 - 3000km"] <- overall_prop
}
for (i in 1: length(levels(MetasubDataPreds$city))){
  this_city <- levels(MetasubDataPreds$city)[i]
  prop <- mean(MetasubDataPreds[MetasubDataPreds$city == this_city,][,"Distance_from_origin"] > 3000 )
  bar_df1[i+1,"> 3000km"] <- prop
  
  overall_prop <- mean(MetasubDataPreds[,"Distance_from_origin"] > 3000)
  bar_df1[ 1,"> 3000km"] <- overall_prop
}
size <- c()
for (i in 1: length(levels(MetasubDataPreds$city))){
  
  this_city <- levels(MetasubDataPreds$city)[i]
  size[i] <- length(which(MetasubDataPreds$city == this_city))
}
```

Fig S1 dist from origin barplot

```{r}
par(xpd = T, mar = par()$mar + c(1,0,0,7), mgp = c(0,0.7,0), las=2)
bp <- barplot(t(bar_df1*100), space = 0,col=c("lightyellow","slategray1","lightblue", "skyblue", "royalblue3", "darkblue"), 
              names.arg=c("Overall",paste0(city_names,"  (",size,")"), axes = FALSE) , 
              las =2, cex.names=.6, ylab = "", axisnames = F, axes = F)
axis(side =2, pos = 0)
mtext(text = c("Overall",paste0(city_names," (",size,")")), side = 1, at = bp, line = 0, padj = 1, cex = 0.7)
title(ylab="Proportion of sample predictions %", mgp=c(0,0,0),cex.lab=1)

legend("topright",inset = c(-0.1,0.4), rev(c(colnames(bar_df1))), 
       fill = rev(c("lightyellow","slategray1","lightblue", "skyblue", "royalblue3", "darkblue")) ,
       bty = 1, cex = 0.8)
par(mar=c(5, 4, 4, 2) + 0.1)

```



Fig S3, effect of sample size on city accurcay

```{r}
#calculate
city_sample_sizes <- data.frame()
for (i in 1:length(levels(MetasubDataPreds$city))){ 
  this_city <- levels(MetasubDataPreds$city)[i]
  city_sample_sizes[i,"city_size"] <-  summary(MetasubDataPreds$city)[this_city]
  city_sample_sizes[i,"within_500"] <-  mean(MetasubDataPreds[MetasubDataPreds$city == this_city,]$Distance_from_origin < 500)
}

#plot
plot(city_sample_sizes$city_size,100*city_sample_sizes[,"within_500"], xlab ="",
     ylab = "", pch = 16, cex = 0.7)
text(city_sample_sizes$city_size ,100*city_sample_sizes[,"within_500"] + 3 ,labels =city_names, cex = 0.6)
lines(lowess(city_sample_sizes$city_size,100*city_sample_sizes[,"within_500"]), col="red")
title(ylab="Predictions within 500km (%)",xlab = "Number of samples from city", mgp=c(2,1,0),cex.lab=1.2)


```



